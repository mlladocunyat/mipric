{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Intentamos analizar de forma previa los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib as plot\n",
    "import nltk "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_table('../inputs/train.tsv')\n",
    "train['len']=train['item_description'].str.len()\n",
    "train['cant']=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(217504739, 1482535)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['item_description_upper']= train['item_description'].str.upper()\n",
    "txtu=train['item_description_upper'].str.cat(sep='.')\n",
    "txt=train['item_description'].str.cat(sep='.')\n",
    "len(txtu),len(train['item_description_upper'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'NO DESCRIPTION YET.THIS KEYBOARD IS IN GREAT CONDITION AND WORKS LIKE IT CAME OUT OF THE BOX. ALL OF THE PORTS ARE TESTED AND WORK PERFECTLY. THE LIGHTS ARE CUSTOMIZABLE VIA THE RAZER SYNAPSE APP ON YOUR PC..ADORABLE TOP WITH A HINT OF LACE AND A KEY HOLE IN THE BACK! THE PALE PINK IS A 1X, AND I AL'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "txtu[0:300]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['NO',\n",
       " 'DESCRIPTION',\n",
       " 'YET.THIS',\n",
       " 'KEYBOARD',\n",
       " 'IS',\n",
       " 'IN',\n",
       " 'GREAT',\n",
       " 'CONDITION',\n",
       " 'AND',\n",
       " 'WORKS',\n",
       " 'LIKE',\n",
       " 'IT',\n",
       " 'CAME',\n",
       " 'OUT',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'BOX',\n",
       " '.',\n",
       " 'ALL',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'PORTS',\n",
       " 'ARE',\n",
       " 'TESTED',\n",
       " 'AND',\n",
       " 'WORK',\n",
       " 'PERFECTLY',\n",
       " '.',\n",
       " 'THE',\n",
       " 'LIGHTS',\n",
       " 'ARE',\n",
       " 'CUSTOMIZABLE',\n",
       " 'VIA',\n",
       " 'THE',\n",
       " 'RAZER',\n",
       " 'SYNAPSE',\n",
       " 'APP',\n",
       " 'ON',\n",
       " 'YOUR',\n",
       " 'PC..ADORABLE',\n",
       " 'TOP',\n",
       " 'WITH',\n",
       " 'A',\n",
       " 'HINT',\n",
       " 'OF',\n",
       " 'LACE',\n",
       " 'AND',\n",
       " 'A',\n",
       " 'KEY',\n",
       " 'HOLE',\n",
       " 'IN',\n",
       " 'THE',\n",
       " 'BACK',\n",
       " '!',\n",
       " 'THE',\n",
       " 'PALE',\n",
       " 'PINK',\n",
       " 'IS',\n",
       " 'A',\n",
       " '1X',\n",
       " ',',\n",
       " 'AND',\n",
       " 'I',\n",
       " 'ALSO',\n",
       " 'HAVE',\n",
       " 'A',\n",
       " '3X',\n",
       " 'AVAILABLE',\n",
       " 'IN',\n",
       " 'WHITE',\n",
       " '!',\n",
       " '.NEW',\n",
       " 'WITH',\n",
       " 'TAGS',\n",
       " '.',\n",
       " 'LEATHER',\n",
       " 'HORSES',\n",
       " '.',\n",
       " 'RETAIL',\n",
       " 'FOR',\n",
       " '[',\n",
       " 'RM',\n",
       " ']',\n",
       " 'EACH',\n",
       " '.',\n",
       " 'STAND',\n",
       " 'ABOUT',\n",
       " 'A',\n",
       " 'FOOT',\n",
       " 'HIGH',\n",
       " '.',\n",
       " 'THEY',\n",
       " 'ARE',\n",
       " 'BEING',\n",
       " 'SOLD',\n",
       " 'AS',\n",
       " 'A',\n",
       " 'PAIR',\n",
       " '.',\n",
       " 'ANY',\n",
       " 'QUESTIONS',\n",
       " 'PLEASE',\n",
       " 'ASK',\n",
       " '.',\n",
       " 'FREE',\n",
       " 'SHIPPING',\n",
       " '.',\n",
       " 'JUST',\n",
       " 'GOT',\n",
       " 'OUT',\n",
       " 'OF',\n",
       " 'STORAGE.COMPLETE',\n",
       " 'WITH',\n",
       " 'CERTIFICATE',\n",
       " 'OF',\n",
       " 'AUTHENTICITY.BANANA',\n",
       " 'REPUBLIC',\n",
       " 'BOTTOMS',\n",
       " ',',\n",
       " 'CANDIES',\n",
       " 'SKIRT',\n",
       " 'WITH',\n",
       " 'MATCHING',\n",
       " 'BLAZER',\n",
       " ',',\n",
       " 'AMY',\n",
       " 'BYERS',\n",
       " 'SUIT',\n",
       " ',',\n",
       " 'LOFT',\n",
       " 'BOTTOMS',\n",
       " 'AND',\n",
       " 'CAMI',\n",
       " 'TOP..SIZE',\n",
       " 'SMALL',\n",
       " 'BUT',\n",
       " 'STRAPS',\n",
       " 'SLIGHTLY',\n",
       " 'SHORTENED',\n",
       " 'TO',\n",
       " 'FIT',\n",
       " 'XS',\n",
       " ',',\n",
       " 'BESIDES',\n",
       " 'THAT',\n",
       " ',',\n",
       " 'PERFECT',\n",
       " 'CONDITION.YOU',\n",
       " 'GET',\n",
       " 'THREE',\n",
       " 'PAIRS',\n",
       " 'OF',\n",
       " 'SOPHIE',\n",
       " 'CHEER',\n",
       " 'SHORTS',\n",
       " 'SIZE',\n",
       " 'SMALL',\n",
       " 'AND',\n",
       " 'MEDIUM',\n",
       " 'GIRLS',\n",
       " 'AND',\n",
       " 'TWO',\n",
       " 'SPORTS',\n",
       " 'BRA/BOY',\n",
       " 'SHORTS',\n",
       " 'SPANDEX',\n",
       " 'MATCHING',\n",
       " 'SETS',\n",
       " 'IN',\n",
       " 'SMALL',\n",
       " 'AND',\n",
       " 'MEDIUM',\n",
       " 'GIRLS',\n",
       " '.',\n",
       " 'ALL',\n",
       " 'ITEMS',\n",
       " 'TOTAL',\n",
       " 'RETAIL',\n",
       " 'FOR',\n",
       " '[',\n",
       " 'RM',\n",
       " ']',\n",
       " 'IN',\n",
       " 'STORE',\n",
       " 'AND',\n",
       " 'YOU',\n",
       " 'CAN',\n",
       " 'TAKE',\n",
       " 'HIM',\n",
       " 'TODAY',\n",
       " 'FOR',\n",
       " 'LESS',\n",
       " 'THAN',\n",
       " 'THE',\n",
       " 'PRICE',\n",
       " 'OF',\n",
       " 'ONE',\n",
       " 'ITEM',\n",
       " 'AT',\n",
       " 'THE',\n",
       " 'STORE',\n",
       " '!',\n",
       " ')',\n",
       " '.GIRLS',\n",
       " 'SIZE',\n",
       " 'SMALL',\n",
       " 'PLUS',\n",
       " 'GREEN',\n",
       " '.',\n",
       " 'THREE',\n",
       " 'SHORTS',\n",
       " 'TOTAL..I',\n",
       " 'REALIZED',\n",
       " 'HIS',\n",
       " 'PANTS',\n",
       " 'ARE',\n",
       " 'ON',\n",
       " 'BACKWARDS',\n",
       " 'AFTER',\n",
       " 'THE',\n",
       " 'PICTURE',\n",
       " '.',\n",
       " 'THEY',\n",
       " 'WERE',\n",
       " 'VERY',\n",
       " 'DIRTY',\n",
       " 'SO',\n",
       " 'I',\n",
       " 'HAND',\n",
       " 'WASHED',\n",
       " 'THEM',\n",
       " '.',\n",
       " 'HE',\n",
       " 'HAS',\n",
       " 'A',\n",
       " 'STUFFED',\n",
       " 'BODY',\n",
       " 'AND',\n",
       " 'PAINTED',\n",
       " 'PORCELAIN',\n",
       " 'HEAD',\n",
       " ',',\n",
       " 'HANDS',\n",
       " 'AND',\n",
       " 'FEET',\n",
       " '.',\n",
       " 'BACK',\n",
       " 'BEFORE',\n",
       " 'CLOWNS',\n",
       " 'WERE',\n",
       " 'TOO',\n",
       " 'SCARY',\n",
       " '.',\n",
       " '9',\n",
       " \"''\",\n",
       " 'TALL',\n",
       " '.',\n",
       " 'NO',\n",
       " 'CHIPS',\n",
       " 'OR',\n",
       " 'CRACKS',\n",
       " 'BUT',\n",
       " 'MINOR',\n",
       " 'PAINT',\n",
       " 'LOSS',\n",
       " 'IN',\n",
       " 'A',\n",
       " 'FEW',\n",
       " 'PLACES',\n",
       " '.',\n",
       " 'CLOWN',\n",
       " 'CIRCUS',\n",
       " 'DOLL',\n",
       " 'COLLECTIBLE.0.25',\n",
       " 'OZ',\n",
       " 'FULL',\n",
       " 'SIZE',\n",
       " 'IS',\n",
       " '1OZ',\n",
       " 'FOR',\n",
       " '[',\n",
       " 'RM',\n",
       " ']',\n",
       " 'IN',\n",
       " 'SEPHORA',\n",
       " '.',\n",
       " '(',\n",
       " '5',\n",
       " ')',\n",
       " 'NEW',\n",
       " 'VS',\n",
       " 'PINK',\n",
       " 'BODY',\n",
       " 'MISTS',\n",
       " '(',\n",
       " '2.5',\n",
       " 'OZ',\n",
       " 'EACH',\n",
       " ')',\n",
       " 'FRESH',\n",
       " '&',\n",
       " 'CLEAN',\n",
       " 'SUN',\n",
       " 'KISS',\n",
       " 'COOL',\n",
       " 'AND',\n",
       " 'BRIGHT',\n",
       " 'TOTAL',\n",
       " 'FLIRT',\n",
       " 'SWEET',\n",
       " 'AND',\n",
       " 'FLIRTY.XL',\n",
       " ',',\n",
       " 'GREAT',\n",
       " 'CONDITION.NO',\n",
       " 'DESCRIPTION',\n",
       " 'YET.AUTHENTIC',\n",
       " '.',\n",
       " 'SUEDE',\n",
       " 'FRINGE',\n",
       " 'BOOTS',\n",
       " '.',\n",
       " 'GREAT',\n",
       " 'CONDITION',\n",
       " '!',\n",
       " 'SIZE',\n",
       " '7',\n",
       " '.',\n",
       " 'IF',\n",
       " 'YOU',\n",
       " 'ARE',\n",
       " 'BETWEEN',\n",
       " 'THE',\n",
       " 'SIZES',\n",
       " '5.5-7',\n",
       " 'AND',\n",
       " 'LOVE',\n",
       " 'WEARING',\n",
       " 'THICK',\n",
       " 'SOCKS',\n",
       " 'DURING',\n",
       " 'THE',\n",
       " 'WINTER',\n",
       " 'THEY',\n",
       " \"'D\",\n",
       " 'BE',\n",
       " 'PERFECT',\n",
       " 'FOR',\n",
       " 'YOU',\n",
       " 'AS',\n",
       " 'WELL',\n",
       " '(',\n",
       " 'I',\n",
       " 'DID',\n",
       " 'LAST',\n",
       " 'WINTER',\n",
       " ')',\n",
       " ':',\n",
       " ')',\n",
       " '.BRAND',\n",
       " 'NEW',\n",
       " '.',\n",
       " 'DELUXE',\n",
       " 'TRAVEL',\n",
       " 'SIZE',\n",
       " 'PRODUCTS',\n",
       " '.',\n",
       " 'CONTAINS',\n",
       " ':',\n",
       " 'AMAZONIAN',\n",
       " 'CLAY',\n",
       " '12',\n",
       " 'HOUR',\n",
       " 'BLUSH',\n",
       " 'IN',\n",
       " 'PAAARTY',\n",
       " '-',\n",
       " '.05OZ/1.5G',\n",
       " 'TARTEIST',\n",
       " 'LIP',\n",
       " 'PAINT',\n",
       " 'IN',\n",
       " 'BIRTHDAY',\n",
       " 'SUIT',\n",
       " '-',\n",
       " '.034OZ/1ML.2',\n",
       " 'GLITTER',\n",
       " 'EYESHADOWS',\n",
       " ';',\n",
       " 'ONE',\n",
       " 'IN',\n",
       " 'BRASS',\n",
       " 'AND',\n",
       " 'ONE',\n",
       " 'IN',\n",
       " 'BLEACHED..BRAND',\n",
       " 'NEW',\n",
       " 'IN',\n",
       " 'BOX',\n",
       " 'SIZE',\n",
       " ':',\n",
       " 'MEDIUM',\n",
       " 'COLOR',\n",
       " ':',\n",
       " 'CORAL',\n",
       " 'RETAILS',\n",
       " 'FOR',\n",
       " '[',\n",
       " 'RM',\n",
       " ']',\n",
       " 'THE',\n",
       " 'BABY',\n",
       " 'K',\n",
       " '’',\n",
       " 'TAN',\n",
       " 'ACTIVE',\n",
       " 'IS',\n",
       " 'MADE',\n",
       " 'OF',\n",
       " 'A',\n",
       " 'BREATHABLE',\n",
       " 'HI-TECH',\n",
       " 'PERFORMANCE',\n",
       " 'FABRIC',\n",
       " 'THAT',\n",
       " 'WICKS',\n",
       " 'AWAY',\n",
       " 'MOISTURE',\n",
       " 'AND',\n",
       " 'SWEAT',\n",
       " ',',\n",
       " 'BLOCKS',\n",
       " 'OVER',\n",
       " '90',\n",
       " '%',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'SUN',\n",
       " '’',\n",
       " 'S',\n",
       " 'HARMFUL',\n",
       " 'UVA',\n",
       " 'AND',\n",
       " 'UVB',\n",
       " 'RAYS',\n",
       " ',',\n",
       " 'AND',\n",
       " 'PROVIDES',\n",
       " 'A',\n",
       " 'UNIQUE',\n",
       " 'TEMPERATURE',\n",
       " 'CONTROL',\n",
       " '.',\n",
       " '-',\n",
       " 'ERGONOMIC',\n",
       " 'POSITIONING',\n",
       " 'FOR',\n",
       " 'HEALTHY',\n",
       " 'INFANT',\n",
       " 'DEVELOPMENT',\n",
       " '.',\n",
       " '-',\n",
       " 'EVENLY',\n",
       " 'DISTRIBUTES',\n",
       " 'WEIGHT',\n",
       " 'ACROSS',\n",
       " 'BACK',\n",
       " 'AND',\n",
       " 'SHOULDERS',\n",
       " '.',\n",
       " '-',\n",
       " 'DOUBLE-LOOP',\n",
       " 'DESIGN',\n",
       " 'SLIPS',\n",
       " 'ON',\n",
       " 'LIKE',\n",
       " 'A',\n",
       " 'T-SHIRT..THIS',\n",
       " 'AUTHENTIC',\n",
       " 'PALLETE',\n",
       " 'BY',\n",
       " 'TOO',\n",
       " 'FACED',\n",
       " 'IS',\n",
       " 'BRAND',\n",
       " 'NEW',\n",
       " 'IN',\n",
       " 'MINT',\n",
       " 'CONDITION',\n",
       " 'STILL',\n",
       " 'IN',\n",
       " 'ORIGINAL',\n",
       " 'BOX',\n",
       " '.',\n",
       " 'IT',\n",
       " \"'S\",\n",
       " 'PART',\n",
       " 'OF',\n",
       " 'THE',\n",
       " '.',\n",
       " 'CHRISTMAS',\n",
       " '2016',\n",
       " 'COLLECTION',\n",
       " '.',\n",
       " 'IT',\n",
       " 'HAS',\n",
       " '12',\n",
       " 'PRETTY',\n",
       " 'EYE',\n",
       " 'SHADOW',\n",
       " 'COLORS',\n",
       " 'AND',\n",
       " 'A',\n",
       " 'SMALL',\n",
       " 'SIZED',\n",
       " \"''\",\n",
       " 'BETTER',\n",
       " 'THAN',\n",
       " 'SEX',\n",
       " \"''\",\n",
       " 'MASCARA',\n",
       " '.',\n",
       " 'NEVER',\n",
       " 'EVEN',\n",
       " 'SWATCHED',\n",
       " '.',\n",
       " 'IMPECCABLE',\n",
       " 'SHAPE',\n",
       " '.',\n",
       " 'PRICE',\n",
       " 'INCLUDES',\n",
       " '2',\n",
       " 'DAY',\n",
       " 'PRIORITY',\n",
       " 'SHIPPING',\n",
       " 'WITH',\n",
       " 'INSURANCE..FANCY',\n",
       " ',',\n",
       " 'DRESSY',\n",
       " 'OR',\n",
       " 'CASUAL',\n",
       " '!',\n",
       " 'DRESS',\n",
       " 'IT',\n",
       " 'UP',\n",
       " 'OR',\n",
       " 'DOWN',\n",
       " '100',\n",
       " '%',\n",
       " 'POLYESTER',\n",
       " ';',\n",
       " 'WASHED',\n",
       " 'ONCE',\n",
       " ',',\n",
       " 'NEVER',\n",
       " 'DRIED',\n",
       " '.',\n",
       " 'SIZE',\n",
       " ':',\n",
       " 'SMALL',\n",
       " 'BRAND',\n",
       " ':',\n",
       " 'LUSH',\n",
       " 'PURCHASED',\n",
       " 'FROM',\n",
       " 'FRANCESCA',\n",
       " \"'S\",\n",
       " 'TAGS',\n",
       " ':',\n",
       " 'FREE',\n",
       " 'PEOPLE',\n",
       " ',',\n",
       " 'ANTHROPOLOGY',\n",
       " ',',\n",
       " 'DRY',\n",
       " 'GOODS',\n",
       " ',',\n",
       " \"FRANCESCA'S.SIZE\",\n",
       " '1',\n",
       " '.',\n",
       " 'WORN',\n",
       " 'ONCE',\n",
       " '.',\n",
       " 'EXCELLENT',\n",
       " 'CONDITION.NWT',\n",
       " 'VICTORIA',\n",
       " \"'S\",\n",
       " 'SECRET',\n",
       " 'ULTIMATE',\n",
       " 'SPORT',\n",
       " 'BRA',\n",
       " '-MAXIMUM',\n",
       " 'SUPPORT',\n",
       " 'SIZE',\n",
       " '34DDD.REASONABLE',\n",
       " 'OFFERS',\n",
       " 'WELCOMED',\n",
       " '.',\n",
       " 'BUT',\n",
       " 'IF',\n",
       " 'YOU',\n",
       " 'ASK',\n",
       " '``',\n",
       " 'LOWEST',\n",
       " \"''\",\n",
       " 'OR',\n",
       " 'LOWBALL',\n",
       " 'I',\n",
       " \"'LL\",\n",
       " 'BLOCK',\n",
       " 'YOU',\n",
       " '...',\n",
       " '-',\n",
       " 'THIS',\n",
       " 'PHONE',\n",
       " 'WAS',\n",
       " 'OPENED',\n",
       " 'UNDER',\n",
       " 'T-MOBILE',\n",
       " 'BUT',\n",
       " 'HAS',\n",
       " 'NOW',\n",
       " 'BEEN',\n",
       " 'UNLOCKED',\n",
       " 'AFTER',\n",
       " 'SWITCHING',\n",
       " 'TO',\n",
       " 'NEW',\n",
       " 'PHONE',\n",
       " '.',\n",
       " '-',\n",
       " 'ALL',\n",
       " 'OF',\n",
       " 'THE',\n",
       " 'BUTTONS',\n",
       " 'ARE',\n",
       " 'FUNCTIONING',\n",
       " 'LIKE',\n",
       " 'NEW',\n",
       " 'STILL',\n",
       " '.',\n",
       " '-',\n",
       " 'IT',\n",
       " \"'S\",\n",
       " 'IN',\n",
       " 'PERFECT',\n",
       " 'USED',\n",
       " 'CONDITION',\n",
       " '-',\n",
       " 'CHECK',\n",
       " 'MY',\n",
       " 'REVIEWS',\n",
       " 'FOR',\n",
       " 'HONEST',\n",
       " 'FEEDBACK',\n",
       " '.',\n",
       " '-',\n",
       " '32GB',\n",
       " ';',\n",
       " 'SORRY',\n",
       " 'NO',\n",
       " 'CHARGER',\n",
       " 'INCLUDED.BRAND',\n",
       " 'NEW',\n",
       " 'NEVER',\n",
       " 'USED',\n",
       " 'ALL',\n",
       " 'COLORS',\n",
       " 'ARE',\n",
       " 'AVAILABLE',\n",
       " 'EACH',\n",
       " 'ONLY',\n",
       " '[',\n",
       " 'RM',\n",
       " ']',\n",
       " '.LANASCLOSET',\n",
       " '~~~',\n",
       " 'DESCRIPTION',\n",
       " ':',\n",
       " 'NEVER',\n",
       " 'WORN',\n",
       " '!',\n",
       " '✨',\n",
       " 'I',\n",
       " 'DELETE/UPDATE',\n",
       " 'MY',\n",
       " 'LISTINGS',\n",
       " 'AND',\n",
       " 'RELIST',\n",
       " 'THEM',\n",
       " 'SO',\n",
       " 'LIKE',\n",
       " 'MY',\n",
       " '“',\n",
       " 'SOLD',\n",
       " '”',\n",
       " 'LISTINGS',\n",
       " 'TO',\n",
       " 'HAVE',\n",
       " 'EASIER',\n",
       " 'ACCESS',\n",
       " 'TO',\n",
       " 'MY',\n",
       " 'SHOP',\n",
       " 'LATER',\n",
       " 'ON',\n",
       " '~~~',\n",
       " '✨',\n",
       " 'I',\n",
       " 'NORMALLY',\n",
       " 'SHIP',\n",
       " 'THE',\n",
       " 'FOLLOWING',\n",
       " 'DAY',\n",
       " ',',\n",
       " 'BUT',\n",
       " 'IT',\n",
       " 'HAPPENS',\n",
       " 'THAT',\n",
       " 'I',\n",
       " 'SHIP',\n",
       " 'A',\n",
       " 'FEW',\n",
       " 'DAYS',\n",
       " 'AFTER',\n",
       " 'PURCHASE',\n",
       " '~~~',\n",
       " 'FOREVER',\n",
       " '21',\n",
       " 'BRANDY',\n",
       " 'MELVILLE',\n",
       " 'BASEBALL',\n",
       " 'TEE.THEY',\n",
       " 'ARE',\n",
       " '100',\n",
       " 'PERCENT',\n",
       " 'AUTHENTIC',\n",
       " '.',\n",
       " 'THEY',\n",
       " 'ARE',\n",
       " 'BEATERS',\n",
       " 'BUT',\n",
       " 'THEY',\n",
       " 'STILL',\n",
       " 'HAVE',\n",
       " 'A',\n",
       " 'LOT',\n",
       " 'OF',\n",
       " 'LIFE',\n",
       " 'IN',\n",
       " 'THEM',\n",
       " '.',\n",
       " 'NO',\n",
       " 'ORIGINAL',\n",
       " 'BOX..BRAND',\n",
       " 'NEW',\n",
       " 'OTTERBOX',\n",
       " 'DEFENDER',\n",
       " 'IPHONE',\n",
       " '6',\n",
       " 'PLUS/6S',\n",
       " 'PLUS.WORN',\n",
       " 'ONE',\n",
       " 'TIME',\n",
       " '.',\n",
       " 'EXCELLENT',\n",
       " 'CONDITION.BEAUTIFUL',\n",
       " 'EXCELLENT',\n",
       " 'CONDITION',\n",
       " 'ZIPS',\n",
       " 'AND',\n",
       " 'TIES',\n",
       " 'IN',\n",
       " 'THE',\n",
       " 'BACK',\n",
       " 'CREAM',\n",
       " 'LINER',\n",
       " 'TOP',\n",
       " 'TO',\n",
       " 'BOTTOM.29W',\n",
       " '.',\n",
       " 'X',\n",
       " '33L',\n",
       " '.',\n",
       " 'SOCIAL',\n",
       " 'STRETCH',\n",
       " 'HOLLISTER',\n",
       " 'JEANS',\n",
       " '***',\n",
       " 'PLEASE',\n",
       " 'SEE',\n",
       " 'PICTURE',\n",
       " '4',\n",
       " ',',\n",
       " 'THE',\n",
       " 'LEATHERS',\n",
       " 'TAG',\n",
       " 'NEAR',\n",
       " 'THE',\n",
       " 'BELT',\n",
       " 'LOOPS',\n",
       " 'IS',\n",
       " 'TORE',\n",
       " 'ALSO',\n",
       " ',',\n",
       " 'AE',\n",
       " 'FAVORITE',\n",
       " 'BOYFRIEND',\n",
       " 'SIZE',\n",
       " '8',\n",
       " 'STRETCH.BNIB',\n",
       " '3',\n",
       " 'FOR',\n",
       " '[',\n",
       " 'RM',\n",
       " ']',\n",
       " 'BETTER',\n",
       " 'THAN',\n",
       " 'SEX',\n",
       " 'WATERPROOF',\n",
       " 'MASCARA',\n",
       " 'TRAVEL',\n",
       " 'SIZE',\n",
       " '4.8G',\n",
       " '/0.17',\n",
       " 'OZ',\n",
       " 'SEE',\n",
       " 'MY',\n",
       " 'OTHER',\n",
       " 'POSTS',\n",
       " 'FOR',\n",
       " '[',\n",
       " 'RM',\n",
       " ']',\n",
       " 'EACH',\n",
       " 'OR',\n",
       " '2',\n",
       " 'FOR',\n",
       " '[',\n",
       " 'RM',\n",
       " ']',\n",
       " '.NO',\n",
       " 'DESCRIPTION',\n",
       " 'YET.PINK',\n",
       " 'BRA',\n",
       " 'WITH',\n",
       " 'LOGO',\n",
       " 'BAND',\n",
       " '!',\n",
       " '36D',\n",
       " 'PUSH',\n",
       " 'UP.NEW',\n",
       " 'UNUSED',\n",
       " 'AND',\n",
       " 'AUTHENTIC',\n",
       " '.',\n",
       " 'CAUDALIE',\n",
       " 'BEAUTY',\n",
       " 'ELIXIR',\n",
       " 'MIST',\n",
       " '.',\n",
       " '1',\n",
       " 'OZ.2',\n",
       " 'BEANIE',\n",
       " 'BABIES',\n",
       " 'PUGSLEY',\n",
       " 'WRINKLES',\n",
       " 'PUPPY',\n",
       " 'WITH',\n",
       " 'PUMPKIN',\n",
       " 'BIG',\n",
       " 'DOG',\n",
       " 'RETRO',\n",
       " 'PINUP',\n",
       " 'DOLL',\n",
       " 'FRILLY',\n",
       " 'SKIRTED',\n",
       " 'ADORABLE',\n",
       " 'BARBIE',\n",
       " 'PINKSUPER',\n",
       " 'CUTE',\n",
       " '!',\n",
       " 'FAN',\n",
       " 'MARTINI',\n",
       " 'CHERRY',\n",
       " 'PINUP',\n",
       " 'ANCHOR',\n",
       " 'MARABOU',\n",
       " '#',\n",
       " 'KITSCHOURE',\n",
       " '#',\n",
       " 'BEASWEETLOLLIPOPINAWORLDOFSOURSUCKERS',\n",
       " 'FROM',\n",
       " 'LOVE',\n",
       " 'IN',\n",
       " 'SUNNY',\n",
       " 'SAN',\n",
       " 'DIEGO',\n",
       " 'CALI-FORNIA',\n",
       " 'US',\n",
       " 'OF',\n",
       " 'A',\n",
       " '!',\n",
       " 'ABSOLUTELY',\n",
       " 'ADORABLE',\n",
       " 'SOFT',\n",
       " 'GENUINE',\n",
       " 'REAL',\n",
       " 'BUNNY',\n",
       " 'FOX',\n",
       " 'FOXY',\n",
       " 'LOXY',\n",
       " 'FUR',\n",
       " 'STUNNING',\n",
       " 'AND',\n",
       " 'GORGEOUS',\n",
       " '!',\n",
       " 'BAMBI',\n",
       " 'LONG',\n",
       " 'EYELASHES',\n",
       " '!',\n",
       " 'SWEET',\n",
       " 'CHEEKS',\n",
       " 'BLUSH',\n",
       " 'PINK',\n",
       " 'JUICY',\n",
       " 'DOLLFACE',\n",
       " '!',\n",
       " 'CANDY',\n",
       " 'COLORS',\n",
       " '!',\n",
       " 'GIRLFRIEND',\n",
       " '.',\n",
       " 'DANCE',\n",
       " 'CLUB',\n",
       " 'BABY',\n",
       " '!',\n",
       " 'PANTY',\n",
       " 'PRESENT',\n",
       " 'FOR',\n",
       " 'THE',\n",
       " 'GIRL',\n",
       " 'WHO',\n",
       " 'HAS',\n",
       " 'EVERYTHING',\n",
       " '!',\n",
       " 'CUPCAKE',\n",
       " 'COUTURE',\n",
       " 'RESIN',\n",
       " 'KAWAII',\n",
       " 'LOLITA',\n",
       " 'DRESS',\n",
       " 'UP',\n",
       " 'GIFT',\n",
       " 'FOR',\n",
       " 'LIME',\n",
       " 'CRIME',\n",
       " 'PEGASUS',\n",
       " 'UNICORN',\n",
       " 'FLAMINGO',\n",
       " 'SWAN',\n",
       " 'PRINCESS',\n",
       " 'KITTY',\n",
       " 'PINUP',\n",
       " 'ROCKABILLY',\n",
       " 'GIRLS',\n",
       " 'JEWELRY',\n",
       " 'AND',\n",
       " 'WILD',\n",
       " 'FOX',\n",
       " 'LOLITA',\n",
       " 'KAWAII',\n",
       " 'GYPSY',\n",
       " 'WEDDING',\n",
       " 'FESTIVAL',\n",
       " 'EDF',\n",
       " 'ELECTRONIC',\n",
       " 'DANCE',\n",
       " 'RAVE',\n",
       " 'RAVER',\n",
       " 'COACHELLA',\n",
       " 'PARTY.ONE',\n",
       " 'SIZE',\n",
       " 'FITS',\n",
       " 'SIZES',\n",
       " '2-12',\n",
       " '92',\n",
       " '%',\n",
       " 'POLYESTER',\n",
       " '8',\n",
       " '%',\n",
       " 'SPANDEX',\n",
       " 'SUPER',\n",
       " 'SOFT',\n",
       " '!',\n",
       " '!',\n",
       " 'CAPRI',\n",
       " 'LEGGINGS',\n",
       " 'HIGH',\n",
       " 'WAIST',\n",
       " ...]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#sent=nltk.sent_tokenize(txt)\n",
    "wordu=nltk.word_tokenize(txtu)\n",
    "wordu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "46209"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Fit the TfidfVectorizer to the training data specifiying a minimum document frequency of 5\n",
    "vect = TfidfVectorizer(min_df=5).fit(wordu)\n",
    "len(vect.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-14-0da235ecf166>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvect\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwordu\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparse2Corpus\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdocuments_columns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mldamodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgensim\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mLdaModel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mid2word\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mid_map\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpasses\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m25\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m34\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mldamodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprint_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_words\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mlc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, corpus, num_topics, id2word, distributed, chunksize, passes, update_every, alpha, eta, decay, offset, eval_every, iterations, gamma_threshold, minimum_probability, random_state, ns_conf, minimum_phi_value, per_word_topics, callbacks, dtype)\u001b[0m\n\u001b[0;32m    396\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcorpus\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    397\u001b[0m             \u001b[0muse_numpy\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatcher\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 398\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcorpus\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunks_as_numpy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0muse_numpy\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    399\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    400\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0minit_dir_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mprior\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mlc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, corpus, chunksize, decay, offset, passes, update_every, eval_every, iterations, gamma_threshold, chunks_as_numpy)\u001b[0m\n\u001b[0;32m    745\u001b[0m                         \u001b[0mpass_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mchunk_no\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlencorpus\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m                     )\n\u001b[1;32m--> 747\u001b[1;33m                     \u001b[0mgammat\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdo_estep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mother\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    748\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    749\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimize_alpha\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mlc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36mdo_estep\u001b[1;34m(self, chunk, state)\u001b[0m\n\u001b[0;32m    558\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mstate\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    559\u001b[0m             \u001b[0mstate\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 560\u001b[1;33m         \u001b[0mgamma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msstats\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minference\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcollect_sstats\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    561\u001b[0m         \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msstats\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msstats\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    562\u001b[0m         \u001b[0mstate\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumdocs\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mgamma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m  \u001b[1;31m# avoids calling len(chunk) on a generator\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mlc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\models\\ldamodel.py\u001b[0m in \u001b[0;36minference\u001b[1;34m(self, chunk, collect_sstats)\u001b[0m\n\u001b[0;32m    480\u001b[0m         \u001b[1;31m# Initialize the variational distribution q(theta|gamma) for the chunk\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    481\u001b[0m         \u001b[0mgamma\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom_state\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m100.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1.\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;36m100.\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnum_topics\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 482\u001b[1;33m         \u001b[0mElogtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdirichlet_expectation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgamma\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    483\u001b[0m         \u001b[0mexpElogtheta\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mElogtheta\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    484\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\mlc\\appdata\\local\\programs\\python\\python36\\lib\\site-packages\\gensim\\matutils.py\u001b[0m in \u001b[0;36mdirichlet_expectation\u001b[1;34m(alpha)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpsi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpsi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 615\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpsi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mpsi\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnewaxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# keep the same precision as input\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "id_map = dict((v, k) for k, v in vect.vocabulary_.items())\n",
    "X = vect.fit_transform(wordu)\n",
    "corpus = gensim.matutils.Sparse2Corpus(X, documents_columns=False)\n",
    "ldamodel = gensim.models.ldamodel.LdaModel(corpus, id2word=id_map, num_topics=10, passes=25, random_state=34)\n",
    "ldamodel.print_topics(num_topics=10, num_words=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(set(sent))*100/len(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=nltk.stem.PorterStemmer()\n",
    "swordu=[stemmer.stem(word) for word in wordu]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(sent),len(wordu),len(set(swordu))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist_wordu = nltk.FreqDist(swordu)\n",
    "fdist_sent = nltk.FreqDist(sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(fdist_sent),len(fdist_wordu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "fdist_sent.plot(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist_sent.most_common(500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fdist_wordu.most_common(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tot_sent=0\n",
    "tot_sent_rep=0\n",
    "for word, freq in fdist_sent.most_common(len(fdist_sent)):\n",
    "    tot_sent+=freq\n",
    "    if freq > 1:\n",
    "        tot_sent_rep+=freq\n",
    "print(tot_sent,tot_sent_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vectorizer = CountVectorizer()\n",
    "\n",
    "corpus = [ 'This is a sentence',\n",
    "           'Another sentence is here',\n",
    "           'Wait for another sentence',\n",
    "           'The sentence is coming',\n",
    "           'The sentence has come'\n",
    "         ]\n",
    "\n",
    "x = vectorizer.fit_transform(corpus)\n",
    "print(pd.DataFrame(x.A, columns=vectorizer.get_feature_names()).to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
